# DeepSeek V3.2 è®­ç»ƒç³»ç»Ÿ

åŸºäº nanochat æ¡†æ¶çš„ DeepSeek V3.2 æ¨¡å‹å®Œæ•´è®­ç»ƒè§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒ DeepSeek Sparse Attention (DSA) å’Œ Mixture of Experts (MoE) æ¶æ„ã€‚

## ğŸš€ ç‰¹æ€§

- **DeepSeek Sparse Attention (DSA)**: é«˜æ•ˆçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ”¯æŒ 128K é•¿ä¸Šä¸‹æ–‡
- **Mixture of Experts (MoE)**: ä¸“å®¶æ··åˆæ¶æ„ï¼Œæé«˜æ¨¡å‹å®¹é‡å’Œæ•ˆç‡
- **å¤šè§„æ¨¡é…ç½®**: æ”¯æŒ small/medium/large/xlarge/full äº”ç§æ¨¡å‹è§„æ¨¡
- **å®Œæ•´è®­ç»ƒé“¾è·¯**: æ•°æ®é¢„å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†å…¨æµç¨‹æ”¯æŒ
- **åˆ†å¸ƒå¼è®­ç»ƒ**: æ”¯æŒå¤šGPUåˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œè®­ç»ƒ
- **å†…å­˜ä¼˜åŒ–**: æ”¯æŒæ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ··åˆç²¾åº¦è®­ç»ƒç­‰ä¼˜åŒ–æŠ€æœ¯

## ğŸ“ é¡¹ç›®ç»“æ„

```
nanochat/
â”œâ”€â”€ nanochat/
â”‚   â”œâ”€â”€ deepseek_config.py      # DeepSeek V3.2 æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ deepseek_attention.py   # DSA ç¨€ç–æ³¨æ„åŠ›å®ç°
â”‚   â”œâ”€â”€ deepseek_moe.py         # MoE ä¸“å®¶æ··åˆå®ç°
â”‚   â”œâ”€â”€ deepseek_model.py       # å®Œæ•´æ¨¡å‹æ¶æ„
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deepseek_train.py       # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ deepseek_data.py        # æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ deepseek_eval.py        # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ deepseek_demo.py        # æ¼”ç¤ºè„šæœ¬
â”‚   â””â”€â”€ ...
â””â”€â”€ DEEPSEEK_V3_2_README.md     # æœ¬æ–‡æ¡£
```

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®ï¼ˆå¦‚æœå°šæœªå…‹éš†ï¼‰
git clone <repository-url>
cd nanochat

# å®‰è£…ä¾èµ–
pip install -e .

# æˆ–è€…ä½¿ç”¨ uvï¼ˆæ¨èï¼‰
uv sync
```

### 2. æ•°æ®å‡†å¤‡

```bash
# å‡†å¤‡ Wikitext æ•°æ®é›†
python scripts/deepseek_data.py --dataset wikitext --max-seq-len 16384

# æˆ–è€…åˆ›å»ºåˆæˆæ•°æ®ç”¨äºæµ‹è¯•
python scripts/deepseek_data.py --synthetic --num-samples 1000 --max-seq-len 4096
```

### 3. æ¨¡å‹è®­ç»ƒ

#### å•GPUè®­ç»ƒï¼ˆå°è§„æ¨¡æ¨¡å‹ï¼‰
```bash
python scripts/deepseek_train.py \
    --model-size small \
    --max-seq-len 4096 \
    --device-batch-size 8 \
    --num-iterations 1000 \
    --run deepseek_small_test
```

#### å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ
```bash
torchrun --nproc_per_node=4 scripts/deepseek_train.py \
    --model-size medium \
    --max-seq-len 8192 \
    --device-batch-size 4 \
    --total-batch-size 131072 \
    --num-iterations 5000 \
    --run deepseek_medium_distributed
```

#### å®Œæ•´è§„æ¨¡è®­ç»ƒï¼ˆéœ€è¦å¤§é‡è®¡ç®—èµ„æºï¼‰
```bash
torchrun --nproc_per_node=8 scripts/deepseek_train.py \
    --model-size large \
    --max-seq-len 16384 \
    --device-batch-size 2 \
    --total-batch-size 262144 \
    --num-iterations 10000 \
    --run deepseek_large_full
```

### 4. æ¨¡å‹è¯„ä¼°

```bash
# è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
python scripts/deepseek_eval.py \
    --model-path ./base_checkpoints/deepseek_small \
    --model-size small \
    --max-seq-len 4096 \
    --output eval_results.json
```

### 5. äº¤äº’å¼æ¼”ç¤º

```bash
# äº¤äº’å¼èŠå¤©
python scripts/deepseek_demo.py --mode interactive --model-size small

# æ‰¹é‡ç”Ÿæˆæµ‹è¯•
python scripts/deepseek_demo.py --mode batch --model-size small

# èƒ½åŠ›æµ‹è¯•
python scripts/deepseek_demo.py --mode test --model-size small
```

## ğŸ“Š æ¨¡å‹é…ç½®

### é¢„å®šä¹‰æ¨¡å‹è§„æ¨¡

| æ¨¡å‹è§„æ¨¡ | å±‚æ•° | éšè—ç»´åº¦ | æ³¨æ„åŠ›å¤´ | æœ€å¤§åºåˆ—é•¿åº¦ | DSA | MoE | å‚æ•°é‡ï¼ˆçº¦ï¼‰ |
|---------|------|----------|----------|--------------|-----|-----|-------------|
| small   | 12   | 768      | 12       | 8K           | âŒ  | âŒ  | 85M         |
| medium  | 24   | 1024     | 16       | 16K          | âœ…  | âŒ  | 250M        |
| large   | 32   | 2048     | 32       | 32K          | âœ…  | âœ…  | 1.2B        |
| xlarge  | 48   | 4096     | 48       | 64K          | âœ…  | âœ…  | 7B          |
| full    | 64   | 8192     | 64       | 128K         | âœ…  | âœ…  | 35B         |

### DeepSeek Sparse Attention (DSA)

DSA æ˜¯ DeepSeek V3.2 çš„æ ¸å¿ƒç‰¹æ€§ï¼Œé€šè¿‡ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶æ˜¾è‘—æé«˜é•¿åºåˆ—å¤„ç†æ•ˆç‡ï¼š

- **å±€éƒ¨çª—å£æ³¨æ„åŠ›**: æ¯ä¸ªtokenåªå…³æ³¨é™„è¿‘çš„token
- **å…¨å±€tokenæ³¨æ„åŠ›**: é€‰æ‹©æ€§å…³æ³¨å…³é”®ä½ç½®çš„token
- **æ»‘åŠ¨çª—å£æœºåˆ¶**: å¹³è¡¡å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯

### Mixture of Experts (MoE)

MoE æ¶æ„é€šè¿‡ä¸“å®¶ç½‘ç»œæé«˜æ¨¡å‹å®¹é‡è€Œä¸æ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬ï¼š

- **å¤šä¸“å®¶ç½‘ç»œ**: æ¯ä¸ªtokené€‰æ‹© top-k ä¸“å®¶
- **åŠ¨æ€è·¯ç”±**: æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©ä¸“å®¶
- **è´Ÿè½½å‡è¡¡**: é˜²æ­¢ä¸“å®¶åˆ©ç”¨ä¸å‡

## âš™ï¸ è®­ç»ƒé…ç½®

### å…³é”®è¶…å‚æ•°

```python
# æ¨¡å‹æ¶æ„
model_size = "medium"      # æ¨¡å‹è§„æ¨¡
max_seq_len = 16384        # æœ€å¤§åºåˆ—é•¿åº¦

# è®­ç»ƒè®¾ç½®
device_batch_size = 8      # å•è®¾å¤‡æ‰¹å¤§å°
total_batch_size = 131072  # æ€»æ‰¹å¤§å°ï¼ˆtokenæ•°ï¼‰
num_iterations = 10000     # è®­ç»ƒæ­¥æ•°

# ä¼˜åŒ–å™¨
embedding_lr = 0.2         # è¯åµŒå…¥å­¦ä¹ ç‡
unembedding_lr = 0.004     # è¾“å‡ºå±‚å­¦ä¹ ç‡
matrix_lr = 0.02           # çŸ©é˜µå‚æ•°å­¦ä¹ ç‡
weight_decay = 0.0         # æƒé‡è¡°å‡

# å­¦ä¹ ç‡è°ƒåº¦
warmup_ratio = 0.1         # é¢„çƒ­æ¯”ä¾‹
warmdown_ratio = 0.2       # å†·å´æ¯”ä¾‹
```

### ç¡¬ä»¶è¦æ±‚å»ºè®®

| æ¨¡å‹è§„æ¨¡ | GPU å†…å­˜ | æ¨è GPU | è®­ç»ƒæ—¶é—´ï¼ˆä¼°è®¡ï¼‰ |
|---------|----------|----------|-----------------|
| small   | 8GB      | RTX 3070 | 2-4å°æ—¶         |
| medium  | 16GB     | RTX 4090 | 8-12å°æ—¶        |
| large   | 32GB     | A100     | 1-2å¤©           |
| xlarge  | 80GB     | H100     | 3-5å¤©           |
| full    | å¤šå¡å¹¶è¡Œ | å¤šH100   | 1-2å‘¨           |

## ğŸ”§ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æ¨¡å‹é…ç½®

```python
from nanochat.deepseek_config import DeepSeekConfig
from nanochat.deepseek_model import create_deepseek_model

# è‡ªå®šä¹‰é…ç½®
custom_config = DeepSeekConfig(
    n_layer=16,
    n_head=20,
    n_embd=1280,
    max_seq_len=32768,
    dsa_enabled=True,
    dsa_window_size=8192,
    moe_enabled=True,
    num_experts=6,
    top_k=2
)

# åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹
model = create_deepseek_model(custom_config)
```

### æ¢å¤è®­ç»ƒ

```bash
python scripts/deepseek_train.py \
    --model-size medium \
    --resume-from-step 5000 \
    --run deepseek_resume
```

### ä½¿ç”¨ WandB ç›‘æ§

è®­ç»ƒè„šæœ¬è‡ªåŠ¨é›†æˆ WandBï¼Œåªéœ€è®¾ç½® `--run` å‚æ•°å³å¯å¼€å§‹æ—¥å¿—è®°å½•ï¼š

```bash
python scripts/deepseek_train.py --run my_experiment --wandb-project deepseek-v3-2
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### å•å…ƒæµ‹è¯•

```bash
# æµ‹è¯• DSA æ³¨æ„åŠ›æœºåˆ¶
python -c "from nanochat.deepseek_attention import test_dsa_attention; test_dsa_attention()"

# æµ‹è¯• MoE å±‚
python -c "from nanochat.deepseek_moe import test_moe_layer; test_moe_layer()"

# æµ‹è¯•å®Œæ•´æ¨¡å‹
python -c "from nanochat.deepseek_model import test_deepseek_model; test_deepseek_model()"
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# å†…å­˜ä½¿ç”¨æµ‹è¯•
python scripts/deepseek_eval.py --model-path ./checkpoints/test --eval-tokens 10000

# æ¨ç†é€Ÿåº¦æµ‹è¯•
python scripts/deepseek_demo.py --mode test --model-size small --max-seq-len 8192
```

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

### é¢„æœŸæ€§èƒ½ï¼ˆåŸºäºç†è®ºè®¡ç®—ï¼‰

| æ¨¡å‹è§„æ¨¡ | å›°æƒ‘åº¦ | BPB | æ¨ç†é€Ÿåº¦ï¼ˆtokens/ç§’ï¼‰ | å†…å­˜ä½¿ç”¨ |
|---------|--------|-----|----------------------|----------|
| small   | 15-20  | 1.2 | 500-800             | 2-4GB    |
| medium  | 10-15  | 0.9 | 200-400             | 6-10GB   |
| large   | 8-12   | 0.7 | 100-200             | 20-30GB  |
| xlarge  | 6-9    | 0.5 | 50-100              | 50-70GB  |
| full    | 4-6    | 0.3 | 20-50               | 150GB+   |

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### DeepSeek Sparse Attention (DSA)

DSA é€šè¿‡ä»¥ä¸‹æœºåˆ¶å®ç°é«˜æ•ˆçš„é•¿åºåˆ—å¤„ç†ï¼š

1. **åˆ†å±‚æ³¨æ„åŠ›**: ç»“åˆå±€éƒ¨å’Œå…¨å±€æ³¨æ„åŠ›
2. **åŠ¨æ€ç¨€ç–æ¨¡å¼**: æ ¹æ®è¾“å…¥åŠ¨æ€è°ƒæ•´æ³¨æ„åŠ›æ¨¡å¼
3. **å†…å­˜ä¼˜åŒ–**: æ˜¾è‘—å‡å°‘æ³¨æ„åŠ›çŸ©é˜µçš„å†…å­˜å ç”¨

### Mixture of Experts (MoE)

MoE æ¶æ„çš„å…³é”®ç‰¹æ€§ï¼š

1. **ä¸“å®¶ä¸“ä¸šåŒ–**: æ¯ä¸ªä¸“å®¶ä¸“æ³¨äºç‰¹å®šç±»å‹çš„æ¨¡å¼
2. **æ¡ä»¶è®¡ç®—**: åªæœ‰è¢«é€‰æ‹©çš„ä¸“å®¶å‚ä¸è®¡ç®—
3. **å¯æ‰©å±•æ€§**: é€šè¿‡å¢åŠ ä¸“å®¶æ•°é‡çº¿æ€§æ‰©å±•æ¨¡å‹å®¹é‡

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: è®­ç»ƒæ—¶å‡ºç°å†…å­˜ä¸è¶³é”™è¯¯**
A: å°è¯•å‡å° `device-batch-size` æˆ– `max-seq-len`ï¼Œå¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

**Q: DSA æ³¨æ„åŠ›åœ¨ CPU ä¸Šè¿è¡Œç¼“æ…¢**
A: åœ¨éCUDAè®¾å¤‡ä¸Šè‡ªåŠ¨ç¦ç”¨ DSAï¼Œä½¿ç”¨æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶

**Q: MoE è®­ç»ƒä¸ç¨³å®š**
A: è°ƒæ•´ä¸“å®¶å®¹é‡å› å­ `expert_capacity_factor`ï¼Œå¢åŠ è¾…åŠ©æŸå¤±æƒé‡

**Q: é•¿åºåˆ—è®­ç»ƒå‡ºç°æ•°å€¼é—®é¢˜**
A: ç¡®ä¿ä½¿ç”¨ bfloat16 ç²¾åº¦ï¼Œæ£€æŸ¥æ—‹è½¬ä½ç½®ç¼–ç çš„æ•°å€¼ç¨³å®šæ€§

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨ CUDA è®¾å¤‡**: DSA å’Œ MoE åœ¨ CUDA ä¸Šæ€§èƒ½æœ€ä½³
2. **å¯ç”¨ç¼–è¯‘ä¼˜åŒ–**: ä½¿ç”¨ `torch.compile` æé«˜è®­ç»ƒé€Ÿåº¦
3. **åˆç†è®¾ç½®æ‰¹å¤§å°**: æ ¹æ® GPU å†…å­˜è°ƒæ•´æ‰¹å¤§å°
4. **ç›‘æ§å†…å­˜ä½¿ç”¨**: ä½¿ç”¨ WandB ç›‘æ§è®­ç»ƒè¿‡ç¨‹ä¸­çš„å†…å­˜ä½¿ç”¨

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. [DeepSeek V3.2: Pushing the Frontier of Open Large Language Models](https://arxiv.org/abs/2512.02556)
2. [DeepSeek Sparse Attention: Efficient Long Sequence Modeling](https://arxiv.org/abs/2512.02557)
3. [Mixture of Experts: Scaling Neural Networks](https://arxiv.org/abs/2401.04088)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº nanochat é¡¹ç›®çš„è®¸å¯è¯ã€‚

---

**æ³¨æ„**: è¿™æ˜¯ä¸€ä¸ªç ”ç©¶æ€§è´¨çš„é¡¹ç›®ï¼Œä¸»è¦ç”¨äºå­¦æœ¯ç ”ç©¶å’Œå®éªŒã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨å‰è¯·è¿›è¡Œå……åˆ†çš„æµ‹è¯•å’ŒéªŒè¯ã€‚